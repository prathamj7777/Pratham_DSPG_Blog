[
  {
    "objectID": "posts/Pratham-Jadhav-Week-One/Pratham-Week-One.html",
    "href": "posts/Pratham-Jadhav-Week-One/Pratham-Week-One.html",
    "title": "Week One Blog",
    "section": "",
    "text": "Week 1 progress\n\nIn first week we did make a presentation on the data set provide about the airport.\nWe made a introduction presentation And we presented it.\nI completed python data camp\nI also worked on R but did not complete the data camp\nI also completed tidyverse part 1 where we learnt about Data Retrieval,Filtering and manipulating data and also Reporting and Visualization.\n\n\nprint(\"Hello\")\n\n[1] \"Hello\"\n\n\n\nlibrary(dplyr)"
  },
  {
    "objectID": "posts/Pratham-Jadhav-Week-Two/Pratham-Week-Two.html",
    "href": "posts/Pratham-Jadhav-Week-Two/Pratham-Week-Two.html",
    "title": "Week Two Blog",
    "section": "",
    "text": "Week 2 progress\n\nIn second Week I learnt about Github\nI installed and used Github\nAnd we were givien task to make repository and blogs about what we did till now in DSPG program\n\n\n\nprint(\"Hello\")\n\n[1] \"Hello\"\n\n\n\nlibrary(dplyr)"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Pratham_DSPG_Blog",
    "section": "",
    "text": "Week four Wrap up\n\n\n\n\n\n\n\n\n\n\n\n\nJun 8, 2023\n\n\nPratham Jadhav\n\n\n\n\n\n\n  \n\n\n\n\nWeek Three Blog\n\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2023\n\n\nPratham Jadhav\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nWeek One Blog\n\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nPratham Jadhav\n\n\n\n\n\n\n  \n\n\n\n\nWeek Two Blog\n\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nPratham Jadhav\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/Pratham-Jadhav-Week-Two/Pratham-week-3/Pratham-Week-Three.html",
    "href": "posts/Pratham-Jadhav-Week-Two/Pratham-week-3/Pratham-Week-Three.html",
    "title": "Week Three Blog",
    "section": "",
    "text": "#Week 3\n1.In week 3 we started working on are project about collecting data about tomatoes,Eggs and Bacon\n2.We started working of web scraping in python"
  },
  {
    "objectID": "posts/Pratham Wrap Up Blog/PrathamWeek4blog.html",
    "href": "posts/Pratham Wrap Up Blog/PrathamWeek4blog.html",
    "title": "Week four Wrap up",
    "section": "",
    "text": "WEEK Four Wrap Up Blog\nDev’s Work\nMonday- Collecting data for the project and working on finding data sources for Heirloom Tomatoes.\nTuesday- Collected in person data at Slater to analyze the housing conditions and amenities there in the first half of the day. Second half was remote where I worked on compiling and cleaning the data.\nWednesday- Created a script which cleaned scraped prices from Fareway Market website for locations Ames, Fort Dodge, Davenport, Iowa City, New Hampton, Clear Lake, Sioux City, Shenandoah in Iowa.\nThursday- Worked to get more data output, discussed presentation and blog wrap ups with team.\n Project overview  \n \n\nThe project aims to address the need for localized and up-to-date demand forecasting information for Iowa’s local food producers.  \nBy combining data and utilizing AI, the project seeks to develop a prototype application that will provide valuable insights to aid producers in making informed decisions about pricing, crop planning, and value-added processing. \n Over the course of three years, the project will progressively build upon previous work, incorporating data from various sources such as historical sales, weather patterns, and market trends.  \n\n\n\nThe ultimate goal is to create a user-friendly tool that empowers farmers with the best information available for improving their local food business and making it more sustainable. \n\n \nPratham’s work\n\nproblem statement:  \n\n\n\"The primary issue at hand is the lack of reliable demand information for local food producers in Iowa, which poses significant challenges in setting optimal prices and planning their operations effectively.\" \n\n \n\"Iowa’s local food producers lack reliable demand information, hindering their pricing and planning decisions. Our project uses AI and data analysis to develop an app that helps farmers forecast demand by considering sales history, weather, and local events. We aim to empower farmers with better decision-making tools and enhance the availability of local food in Iowa.\" \n \n\n In response, our project employs cutting-edge artificial intelligence and advanced data analysis techniques to develop a sophisticated application.  \nThis application serves as a valuable tool for farmers, enabling them to make accurate demand forecasts by considering critical factors such as historical sales data, weather patterns, and local events.  \n\n\n\nBy equipping farmers with enhanced decision-making capabilities, our goal is to empower them and facilitate the wider availability of locally produced food across Iowa. \n\n\n\nAaron’s Work\nThis is the scraper for Fresh Thyme Market using scrapy python package\n\n```{python}\n\n#|eval=FALSE\n\nfrom datetime import datetime\n\nimport pandas as pd\n\nimport scrapy\n\nfrom scrapy.crawler import CrawlerProcess\n\nfrom scrapy.utils.log import configure_logging\n \nclass FreshThymeSpider(scrapy.Spider):\n\n    name = ‘Fresh Thyme Market Spider’\n \n    def start_requests( self ):\n\n        #Bacon Scraper part\n\n        bacon_urls = [’https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage’,\n\n                      ’https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Bacon&take=48&f=Category%3AHot+Dogs%2C+Bacon+%26+Sausage’]\n\n        for url in bacon_urls:\n\n            yield scrapy.Request( url = url, callback = self.cardsParse, meta={‘type’: ‘bacon’, ‘url’: url})\n \n        #Egg Scraper part\n\n        egg_urls = [’https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=Eggs&take=48&f=Category%3AEggs’,\n\n                      ’https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=Eggs&take=48&f=Category%3AEggs’]\n\n        for url in egg_urls:\n\n            yield scrapy.Request( url = url, callback = self.cardsParse, meta={‘type’: ‘egg’, ‘url’: url})\n \n        #Heirloom Tomatoes part\n\n        tomato_urls = [’https://ww2.freshthyme.com/sm/planning/rsid/951/results?q=heirloom%20tomatoes’,\n\n                       ’https://ww2.freshthyme.com/sm/planning/rsid/952/results?q=heirloom%20tomatoes’]\n \n        for url in tomato_urls:\n\n            yield scrapy.Request( url = url, callback = self.cardsParse, meta={‘type’: ‘tomato’, ‘url’: url})\n \n    def cardsParse(self, response):\n\n        #Failsafe for links\n\n        try:\n\n            #grabs the store location\n\n            storeXpath = ‘//*[contains(@class,“HeaderSubtitle”)]/text()’\n\n            store = response.xpath(storeXpath).extract_first()\n\n            #grabs all cards from list and saves the link to follow\n\n            xpath = ‘//*[contains(@class,“Listing”)]/div/a/@href’\n\n            listCards = response.xpath(xpath)\n\n            for url in listCards:\n\n                yield response.follow( url = url, callback = self.itemParse, meta={‘store’: store, ‘type’: response.meta.get(‘type’), ‘url’: response.meta.get(‘url’)} )\n\n        except AttributeError:\n\n           pass\n\n\n    def itemParse(self, response):\n\n        #xpaths to extract \n\n        nameXpath = ‘//*[contains(@class, “PdpInfoTitle”)]/text()’\n\n        priceXpath = ‘//*[contains(@class, “PdpMainPrice”)]/text()’\n\n        unitPriceXpath = ‘//*[contains(@class, “PdpPreviousPrice”)]/text()’\n\n        prevPriceXpath = ‘//*[contains(@class, “PdpUnitPrice”)]/text()’\n\n        #Adding the data to data frame\n\n        itemType = response.meta.get(‘type’)\n\n        if(itemType == “bacon”):\n\n            baconFrame.loc[len(baconFrame)] = [response.xpath(nameXpath).extract_first(),\n\n                                               response.xpath(priceXpath).extract_first(), \n\n                                               response.xpath(unitPriceXpath).extract_first(), \n\n                                               response.xpath(prevPriceXpath).extract_first(), \n\n                                               response.meta.get(‘store’),\n\n                                               response.meta.get(‘url’)]\n\n        elif(itemType == “egg”):\n\n            eggFrame.loc[len(eggFrame)] = [response.xpath(nameXpath).extract_first(),\n\n                                           response.xpath(priceXpath).extract_first(), \n\n                                           response.xpath(prevPriceXpath).extract_first(), \n\n                                           response.meta.get(‘store’),\n\n                                           response.meta.get(‘url’)]\n\n        elif(itemType == “tomato”):\n\n            tomatoFrame.loc[len(tomatoFrame)] = [response.xpath(nameXpath).extract_first(),\n\n                                                 response.xpath(priceXpath).extract_first(), \n\n                                                 response.xpath(prevPriceXpath).extract_first(), \n\n                                                 response.meta.get(‘store’),\n\n                                                 response.meta.get(‘url’)]\n \n# Start\n\n#DEBUG Switch\n\nDEBUG = 0\n \n#Data frames\n\nbaconFrame = pd.DataFrame(columns=[‘Bacon’, ‘Current Price’, ‘Unit Price’, ‘Sale’, ‘Store Location’, ‘Url’])\n\neggFrame = pd.DataFrame(columns=[‘Egg’, ‘Current Price’, ‘Sale’, ‘Store Location’, ‘Url’])\n\ntomatoFrame = pd.DataFrame(columns=[‘Heirloom Tomato’, ‘Current Price’, ‘Sale’, ‘Store Location’, ‘Url’])\n \nif(DEBUG):\n\n    #To see the inner mechanics of the spider\n\n    configure_logging()\n \n#This is to start the spider\n\nprocess = CrawlerProcess()\n\nprocess.crawl(FreshThymeSpider)\n\nprocess.start()\n\nprocess.stop()\n \nif(DEBUG):\n\n    #To see the outputs\n\n    print(baconFrame)\n\n    print(eggFrame)\n\n    print(tomatoFrame)\n \n#Adds the date that the data was scraped\n\ncurrentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n\n#To CSV files\n\nbaconFrame.to_csv(currentDate + “Fresh Thyme Bacon.csv”)\n\neggFrame.to_csv(currentDate + “Fresh Thyme Egg.csv”)\n\ntomatoFrame.to_csv(currentDate + “Fresh Thyme Heirloom Tomatoes.csv”)\n\n```\n \n\n\nThis is the scraper for Hyvee made using selenium python package\n\n```{python}\n\n#|eval=FALSE\n\n#Imports\n\nfrom datetime import datetime\n\nimport pandas as pd\n\n#Imports for Scraping\n\nfrom selenium import webdriver\n\nfrom selenium.webdriver.firefox.service import Service as FirefoxService\n\nfrom webdriver_manager.firefox import GeckoDriverManager\n\nfrom selenium.common.exceptions import NoSuchElementException\n\nfrom selenium.common.exceptions import StaleElementReferenceException\n\nfrom selenium.webdriver.common.by import By\n\nfrom selenium.webdriver.support.ui import WebDriverWait\n\nfrom selenium.webdriver.support import expected_conditions as EC\n\nfrom os import path\n\nimport time\n \n\n\nclass HyveeSpider():\n\n    name = “Hyvee Spider”\n\n    baconFrame = pd.DataFrame(columns=[‘Bacon’, ‘Current Price’, ‘Sale’, ‘Weight’, ‘Url’])\n\n    eggFrame = pd.DataFrame(columns=[‘Egg’, ‘Current Price’, ‘Sale’, ‘Amount’, ‘Url’])\n\n    tomatoFrame = pd.DataFrame(columns=[‘Heirloom Tomato’, ‘Current Price’, ‘Sale’, ‘Weight’, ‘Url’])\n\n\n    def __init__(self):\n\n        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n\n        self.baconUrls = [’https://www.hy-vee.com/aisles-online/p/11315/Hormel-Black-Label-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/47128/Hormel-Black-Label-Fully-Cooked-Original-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/41626/Applegate-Naturals-Uncured-Sunday-Bacon-Hickory-Smoked’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/57278/HyVee-Double-Smoked-Thick-Sliced-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2405550/Applegate-Naturals-No-Sugar-Uncured-Bacon-Hickory-Smoked’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/57279/HyVee-Sweet-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/11366/Hormel-Black-Label-Original-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2455081/Jimmy-Dean-Premium-Hickory-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/3595492/Farmland-Bacon-Double-Smoked-Double-Thick-Cut’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/47117/Hormel-Black-Label-Center-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/57277/HyVee-Center-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2199424/Country-Smokehouse-Thick-Applewood-Slab-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/77228/Hormel-Black-Label-Original-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/21239/Farmland-Naturally-Hickory-Smoked-Classic-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2456254/Jimmy-Dean-Premium-Applewood-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/21240/Farmland-Naturally-Hickory-Smoked-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/47159/Hormel-Black-Label-Original-Bacon-4Pk’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/50315/Oscar-Mayer-Naturally-Hardwood-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/50321/Oscar-Mayer-Center-Cut-Original-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/50316/Oscar-Mayer-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2199421/Country-Smokehouse-Thick-Hickory-Smoked-Slab-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/104466/Hickory-Country-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/23975/HyVee-Hickory-House-Applewood-Naturally-Smoked-Thick-Sliced-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/23949/HyVee-Sweet-Smoked-Thick-Sliced-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/23963/HyVee-Fully-Cooked-Hickory-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/11173/Hormel-Black-Label-Applewood-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/21317/Farmland-Naturally-Applewood-Smoked-Classic-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/21238/Farmland-Naturally-Hickory-Smoked-Thick-Cut-Bacon-Package’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/23948/HyVee-Lower-Sodium-Sweet-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/458259/Wright-Naturally-Hickory-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/11384/Hormel-Natural-Choice-Uncured-Original-Bacon-12-oz’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2476490/Jimmy-Dean-FC-Hickory-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/1646677/Smithfield-Hometown-Original-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/53849/Farmland-Naturally-Hickory-Smoked-Lower-Sodium-Classic-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/47121/Hormel-Black-Label-Maple-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/164627/Oscar-Mayer-Fully-Cooked-Original-Bacon-252-oz-Box’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/23974/HyVee-Hickory-House-Hickory-Smoked-Thick-Sliced-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/50319/Oscar-Mayer-Selects-Smoked-Uncured-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2471760/Jimmy-Dean-FC-Applewood-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/16239/Oscar-Mayer-Center-Cut-Thick-Sliced-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2214511/Hormel-Black-Label-Original-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/1008152/Wright-Naturally-Smoked-Applewood-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/1813260/Smithfield-Naturally-Hickory-Smoked-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/23976/HyVee-Hickory-House-Peppered-Naturally-Smoked-Thick-Sliced-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/21320/Farmland-Naturally-Applewood-Smoked-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/21253/Farmland-Naturally-Hickory-Smoked-Extra-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/1255920/Hormel-Black-Label-Cherrywood-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/57304/HyVee-Blue-Ribbon-Maple-Naturally-Smoked-Thick-Sliced-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/21252/Farmland-Naturally-Hickory-Smoked-30-Less-Fat-Center-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2501872/Bourbon-And-Brown-Sugar-Slab-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/2516586/Hormel-Natural-ChoiceOriginal-Thick-Cut-Uncured-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/21319/Farmland-Naturally-Hickory-Smoked-Double-Smoked-Classic-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/317829/Des-Moines-Bacon-And-Meat-Company-Hardwood-Smoked-Uncured-Country-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/1255919/Hormel-Black-Label-Jalapeno-Thick-Cut-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/3538865/Oscar-Mayer-Bacon-Thick-Cut-Applewood’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/317830/Des-Moines-Bacon-And-Meat-Company-Applewood-Smoked-Bacon’,\n\n                     ’https://www.hy-vee.com/aisles-online/p/3308731/Oscar-Mayer-Natural-Fully-Cooked-Uncured-Bacon’\n\n                     ]\n\n        self.eggsUrls = [’https://www.hy-vee.com/aisles-online/p/57236/HyVee-Grade-A-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/23899/HyVee-Grade-A-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/715446/Farmers-Hen-House-Free-Range-Organic-Large-Brown-Grade-A-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/2849570/Thats-Smart-Large-Shell-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/31351/Farmers-Hen-House-Free-Range-Grade-A-Large-Brown-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/23900/HyVee-Grade-A-Extra-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/71297/Egglands-Best-Farm-Fresh-Grade-A-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/36345/Egglands-Best-Grade-A-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/3192325/HyVee-Free-Range-Large-Brown-Egg-Grade-A’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/23903/HyVee-Grade-A-Jumbo-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/3192323/HyVee-Cage-Free-Large-Brown-Egg-Grade-A’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/36346/Egglands-Best-Cage-Free-Brown-Grade-A-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/3192322/HyVee-Cage-Free-Large-Brown-Egg-Grade-A’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/858343/HyVee-Cage-Free-Omega3-Grade-A-Large-Brown-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/1901565/Farmers-Hen-House-Pasture-Raised-Organic-Grade-A-Large-Brown-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/60364/HyVee-HealthMarket-Organic-Grade-A-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/71298/Egglands-Best-Extra-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/23902/HyVee-Grade-A-Extra-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/453006/Egglands-Best-XL-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/2668550/HyVee-One-Step-Pasture-Raised-Large-Brown-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/66622/Farmers-Hen-House-Jumbo-Brown-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/3274825/Nellies-Eggs-Brown-Free-Range-Large’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/57235/HyVee-Grade-A-Medium-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/2437128/Pete-And-Gerrys-Eggs-Organic-Brown-Free-Range-Large’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/36347/Egglands-Best-Organic-Cage-Free-Grade-A-Large-Brown-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/2698224/Nellies-Free-Range-Eggs-Large-Fresh-Brown-Grade-A’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/57237/HyVee-Grade-A-Large-Eggs’,\n\n                    ’https://www.hy-vee.com/aisles-online/p/190508/Farmers-Hen-House-Organic-Large-Brown-Eggs’\n\n                   ]\n\n        self.tomatoesUrls = [’https://www.hy-vee.com/aisles-online/p/37174/’]\n\n        self.count = 0\n \n    def dataWait(self, xpath):\n\n        ignored_exceptions=(NoSuchElementException,StaleElementReferenceException,)\n\n        element = WebDriverWait(self.driver, 3, ignored_exceptions=ignored_exceptions).until(EC.visibility_of_element_located((By.XPATH, xpath))).text\n\n        return element\n\n\n    def dataWaitForAll(self, xpath):\n\n            ignored_exceptions=(NoSuchElementException,StaleElementReferenceException,)\n\n            elements = WebDriverWait(self.driver, 30, ignored_exceptions=ignored_exceptions).until(EC.visibility_of_all_elements_located((By.XPATH, xpath)))\n\n            return len(elements)\n \n    def restart(self):\n\n        self.driver.close()\n\n        self.driver.quit()\n\n        self.driver = webdriver.Firefox(service=FirefoxService(GeckoDriverManager().install(), log_path=path.devnull))\n \n    def start_requests( self ):\n\n        attemps = 3\n \n        self.count = 0\n\n        for trying in range(attemps):\n\n            try:\n\n                self.requestBacon()\n\n                print(“Bacon Finished”)\n\n                break\n\n            except:\n\n                print(“Bacon Export Failed Recovering extraction and continueing”)\n\n                self.restart()        \n\n        self.count = 0\n\n        for trying in range(attemps):\n\n            try:\n\n                self.requestEgg()\n\n                print(“Eggs Finished”)\n\n                break\n\n            except:\n\n                print(“Eggs Export Failed. Recovering extraction and continueing”)\n\n                self.restart()  \n\n\n        self.count = 0\n\n        for trying in range(attemps):\n\n            try:\n\n                self.requestTomato()\n\n                print(“Heirloom Tomatoes Successfully Finished”)\n\n                break\n\n            except:\n\n                print(“Tomatoes Export Failed Recovering extraction and continueing”)\n\n                self.restart()\n\n\n        self.driver.close()\n\n        self.driver.quit()\n \n    def requestBacon( self ):\n\n        total = len(self.baconUrls)\n\n        while self.count < total:\n\n            url = self.baconUrls[self.count]\n\n            self.driver.get(url)\n\n            time.sleep(1) # marionette Error Fix\n\n            pXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p’\n\n            nameXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/h1’\n\n            priceXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[1]’\n\n            sale = self.dataWaitForAll(pXpath) #Ensures the page is loaded\n\n            name = self.dataWait(nameXpath) \n\n            price = self.dataWait(priceXpath)\n\n            if sale == 2:\n\n                weightXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[2]’\n\n                weight = self.dataWait(weightXpath)\n\n                self.baconFrame.loc[len(self.baconFrame)] = [name,\n\n                                                price,\n\n                                                “False”,\n\n                                                weight,\n\n                                                url]\n\n            elif sale == 3:\n\n                prevPriceXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[2]’\n\n                weightXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[3]’\n\n                prevPrice = self.dataWait(prevPriceXpath)\n\n                weight = self.dataWait(weightXpath)\n\n                self.baconFrame.loc[len(self.baconFrame)] = [name,\n\n                                                price,\n\n                                                prevPrice,\n\n                                                weight,\n\n                                                url]\n\n            else:\n\n                # Catch if there is anything missing elements\n\n                self.baconFrame.loc[len(self.baconFrame)] = [“SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   url]\n\n            self.count += 1\n\n            print(“Bacon item added”, self.count,” of “, total,” :  “, name)\n\n        self.count = 0\n \n    def requestEgg(self): \n\n        total = len(self.eggsUrls)\n\n        while self.count < total:\n\n            url = self.eggsUrls[self.count]\n\n            self.driver.get(url)\n\n            time.sleep(1) # marionette Error Fix\n\n            pXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p’\n\n            nameXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/h1’\n\n            priceXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[1]’\n\n            sale = self.dataWaitForAll(pXpath) #Ensures the page is loaded\n\n            name = self.dataWait(nameXpath) \n\n            price = self.dataWait(priceXpath)\n\n            if sale == 2:\n\n                weightXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[2]’\n\n                weight = self.dataWait(weightXpath)\n\n                self.eggFrame.loc[len(self.eggFrame)] = [name,\n\n                                                price,\n\n                                                “False”,\n\n                                                weight,\n\n                                                url]\n\n            elif sale == 3:\n\n                prevPriceXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[2]’\n\n                weightXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[3]’\n\n                prevPrice = self.dataWait(prevPriceXpath)\n\n                weight = self.dataWait(weightXpath)\n\n                self.eggFrame.loc[len(self.eggFrame)] = [name,\n\n                                                price,\n\n                                                prevPrice,\n\n                                                weight,\n\n                                                url]\n\n            else:\n\n                # Catch if there is anything missing elements\n\n                self.eggFrame.loc[len(self.eggFrame)] = [“SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   url]\n\n            self.count += 1\n\n            print(“Eggs item added”, self.count,” of “, total,” :  “, name)\n\n        self.count = 0\n \n    def requestTomato( self ):\n\n        total = len(self.tomatoesUrls)\n\n        while self.count < total:\n\n            url = self.tomatoesUrls[self.count]\n\n            self.driver.get(url)\n\n            time.sleep(1) # marionette Error Fix\n\n            pXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p’\n\n            nameXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/h1’\n\n            priceXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[1]’\n\n            sale = self.dataWaitForAll(pXpath) #Ensures the page is loaded\n\n            name = self.dataWait(nameXpath) \n\n            price = self.dataWait(priceXpath)\n\n            if sale == 2:\n\n                weightXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[2]’\n\n                weight = self.dataWait(weightXpath)\n\n                self.tomatoFrame.loc[len(self.tomatoFrame)] = [name,\n\n                                                price,\n\n                                                “False”,\n\n                                                weight,\n\n                                                url]\n\n            elif sale == 3:\n\n                prevPriceXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[2]’\n\n                weightXpath = ‘//*[contains(@class, “product-details_detailsContainer”)]/p[3]’\n\n                prevPrice = self.dataWait(prevPriceXpath)\n\n                weight = self.dataWait(weightXpath)\n\n                self.tomatoFrame.loc[len(self.tomatoFrame)] = [name,\n\n                                                price,\n\n                                                prevPrice,\n\n                                                weight,\n\n                                                url]\n\n            else:\n\n                # Catch if there is anything missing elements\n\n                self.tomatoFrame.loc[len(self.tomatoFrame)] = [“SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   “SKIPPED”,\n\n                                                   url]\n\n            self.count += 1\n\n            print(“Tomato item added”, self.count,“of”, total, “: ”, name)\n\n        self.count = 0\n \n# Start\n\nspider = HyveeSpider()\n\nspider.start_requests()\n\n#Adds the date that the data was scraped\n\ncurrentDate = str(datetime(datetime.today().year, datetime.today().month, datetime.today().day))[:-8]\n\n#To CSV files\n\nspider.baconFrame.to_csv(currentDate + “Hyvee Bacon.csv”)\n\nspider.eggFrame.to_csv(currentDate + “Hyvee Egg.csv”)\n\nspider.tomatoFrame.to_csv(currentDate + “Hyvee Heirloom Tomatoes.csv”)\n\n\n\nWeek 4 (Current Week): Data Collection and Preprocessing \n\nDuring this week, the team is focused on collecting the necessary data from identified sources. The collected data will undergo preprocessing tasks such as cleaning, transforming, and formatting to ensure its suitability for analysis and modeling. \n\nWeek 5 (Next Week): Exploratory Data Analysis and Feature Engineering \n\nIn the upcoming week, the team will perform exploratory data analysis to gain insights into the collected data. Statistical techniques and visualization methods will be employed to understand the distribution, patterns, and relationships within the data. Feature engineering techniques will also be applied to extract relevant features and create new variables that enhance the predictive power of the model. \n\nWeek 6: Model Development - Building and Training the Machine Learning Model \n\nFollowing the exploratory data analysis, the team will move on to developing the machine learning model for demand forecasting. Suitable algorithms will be selected based on the problem’s nature and the available data. The chosen model(s) will be implemented and trained using the preprocessed data, with model parameters fine-tuned for optimal performance. \n \n\nWeek 7: Model Evaluation, Fine-tuning, and Validation \n\nDuring this phase, the trained models will be rigorously evaluated to measure their performance and predictive capabilities. Various evaluation metrics will be calculated to assess the model’s effectiveness. The team will further fine-tune the model, adjusting parameters or exploring ensemble techniques to improve its performance. Validation techniques, such as holdout sets or cross-validation, will be employed to ensure the model’s generalizability and reliability. \n \n\nWeek 8: Final Testing, Presentation Preparation, and Documentation \n\nIn the final week, the developed model will undergo thorough testing to ensure its stability and accuracy in predicting demand for local food products. The team will prepare a comprehensive presentation summarizing the project’s objectives, methodology, findings, and recommendations. Documentation of the project, including the data collection process, preprocessing steps, modeling techniques, and results, will also be completed. \n \nThese future and next steps will allow the team to progress through the remaining weeks, effectively building and evaluating the machine learning model for demand forecasting in the local food industry. \n \n \nFuture scope:  \nthe future scope of the project lies in expanding the application’s capabilities, incorporating additional data sources, refining the machine learning models, and fostering collaboration within the local food ecosystem. By continually improving and adapting the solution, the project can contribute to the sustainable growth and success of Iowa’s local food producers."
  }
]